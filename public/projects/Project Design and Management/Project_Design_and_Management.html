<p>
    This project focused on <strong>improving the user experience</strong> for
    <a href="https://fondoambiente.it/"> Fondo Ambiente Italiano (FAI) </a>
    , a non-profit organization dedicated to protecting and promoting Italy's
    natural and cultural heritage. The primary objective was to
    <strong>assess the desirability of potential solutions</strong> that address
    user needs, particularly for <em>active seniors</em> navigating the FAI
    website to discover and participate in cultural events.
</p>
<p>
    Through comprehensive research and analysis, me and my team
    <strong
        >identified user groups, validated their needs, and developed three
        innovative solutions</strong
    >: an <em>interactive map</em> for event discovery, a
    <em>customizable email notification system</em>, and an
    <em>AI-powered conversational chatbot</em>. Each solution was tested and
    assessed using quantitative metrics including time efficiency, user
    satisfaction, engagement levels, and technical feasibility.
</p>

<h2>What I Learned</h2>
<p>
    This project provided insights into the
    <strong>complete product design and management lifecycle</strong>, from user
    research to solution implementation and assessment. One of the most
    significant learnings was the importance of
    <strong>combining top-down and bottom-up research approaches</strong> to
    gain comprehensive user insights. The website analysis gave us FAI's
    organizational perspective, while social network analysis and user comments
    revealed genuine pain points that users experienced during major events like
    <em>FAI Autumn Days</em>.
</p>
<p>
    I learned the critical value of
    <strong>structured ideation methods</strong>. Techniques like
    <a href="https://www.mural.co/blog/round-robin">
        Round-Robin Brainstorming
    </a>
    ,
    <a href="https://miro.com/brainstorming/what-is-brainwriting/">
        Brain-Writing
    </a>
    , and the
    <a href="https://en.wikipedia.org/wiki/Nominal_group_technique">
        Nominal Group Technique
    </a>
    helped our team generate diverse ideas while
    <strong>mitigating common brainstorming pitfalls</strong> such as groupthink
    and dominant personalities. The integration of AI tools like
    <em>ChatGPT</em> for idea expansion demonstrated how generative AI can
    augment human creativity when used strategically with well-engineered
    prompts.
</p>
<p>
    The need hypothesis validation process taught me the importance of
    <strong>designing testable, precise, and measurable experiments</strong>. We
    structured our hypotheses using the format
    <em>"We believe that... So if... Then..."</em> which forced us to think
    critically about validation criteria before conducting experiments. This
    approach helped us
    <strong>avoid the common pitfall of confirmation bias</strong> and ensured
    we collected meaningful data.
</p>
<p>
    User testing revealed
    <strong>surprising insights that challenged our initial assumptions</strong
    >. For instance, we expected the
    <a href="https://www.nationaltrust.org.uk/"> UK National Trust website </a>
    to outperform FAI's site due to its additional features, but users actually
    found it more confusing. This taught me that
    <strong>more features do not always equal better user experience</strong>, a
    critical lesson in product design. Users simply wanted to find relevant
    events quickly, and excessive tools sometimes hindered rather than helped.
</p>
<p>
    The assessment methodology was particularly enlightening. Creating a
    <em>Quality Index</em> that combined time metrics with user satisfaction
    (using logarithmic transformation) provided a nuanced view of solution
    effectiveness. The <strong>final scoring formula</strong> that incorporated
    time, satisfaction, engagement, and feasibility demonstrated how
    <strong
        >multi-dimensional assessment can lead to more informed
        decision-making</strong
    >
    than relying on a single metric.
</p>
<p>
    Working with real users through the
    <a href="https://en.wikipedia.org/wiki/Think_aloud_protocol">
        Thinking Aloud
    </a>
    technique revealed
    <strong
        >the gap between what users say they want and what they actually
        need</strong
    >. Their spontaneous comments during navigation tasks provided authentic
    insights that traditional surveys might have missed. This experience
    reinforced the value of observational research methods in UX design.
</p>
<p>
    I also learned about the
    <strong>challenges of implementing AI solutions</strong> in real-world
    contexts. While our <em>VirgilioGPT</em> chatbot scored well on engagement
    and satisfaction, its feasibility was limited by slow response times when
    searching the internet. This highlighted the importance of
    <strong>balancing innovation with practical constraints</strong>, and the
    need to consider technical limitations early in the design process.
</p>
<p>
    Finally, this project demonstrated the importance of
    <strong>consensus-building and majority-voting systems</strong> in team
    decision-making. We successfully navigated complex choices by combining
    structured discussion with democratic voting, ensuring all team members felt
    heard while maintaining project momentum.
</p>

<h2>Research Methodology</h2>

<p>
    The research employed a
    <strong
        >mixed-method approach combining top-down and bottom-up
        strategies</strong
    >
    to identify users and their needs. The team evaluated seven potential
    research methods using a structured assessment matrix that scored each
    method on feasibility, efficiency, and effectiveness. This analysis led to
    the selection of <strong>three primary methods</strong>:
    <em>website analysis, social network analysis, and benchmarking</em>.
</p>

<p>
    The website analysis revealed
    <strong>critical insights into FAI's existing user base</strong> through
    examination of membership categories. The Italian version of the website
    proved significantly richer in content than the English version, featuring
    prominent calls-to-action for membership enrollment. Analysis of FAI's
    financial statements showed that
    <strong>membership represents the most significant income source</strong>
    after donations, validating the importance of understanding and serving
    these user segments effectively.
</p>

<p>
    The team conducted a detailed analysis of <em>FAI's Facebook page</em>,
    examining posts from October to identify engagement patterns and demographic
    information. Through systematic cataloging of post themes and quantitative
    analysis of reactions and comments, the research revealed that
    <strong
        >users aged 30-40, 50-60, and 60-70 showed the highest engagement
        levels</strong
    >. Critical insights emerged from analyzing negative comments during
    <em>FAI Autumn Days</em>, which revealed specific pain points including
    unclear ticket pricing, poor coordination, and long wait times without
    reservation systems.
</p>

<p>
    Comparative analysis with organizations like the
    <em>UK's National Trust</em> and
    <em>France's Centre des Monuments Nationaux</em> provided valuable insights
    into best practices for heritage site management. The UK's National Trust,
    with over 5.6 million members and annual income exceeding Â£680 million,
    demonstrated successful engagement strategies. This analysis
    <strong>identified potential user groups not yet fully served by FAI</strong
    >, including eco-tourists, photographers and artists, and digital content
    consumers, while also revealing opportunities such as implementing
    restaurants at FAI locations.
</p>

<h2>User Needs Validation</h2>
<p>
    The team identified <strong>six primary user categories</strong>:
    <em
        >Professionals with Cultural and Travel Interests, Active Seniors,
        Cultural Enthusiasts, Foreign Tourists, Experience-Seeking Tourists, and
        Recreation and Fitness Groups</em
    >. Each group had distinct needs ranging from personalized trip
    customization to enhanced event comparison tools.
</p>

<p>
    Using <em>Brain-Writing technique</em> combined with the
    <em>Nominal Group Technique</em>, the team formulated
    <strong>testable need hypotheses</strong> following the structure
    <em>"We believe that... So if... Then..."</em>. Each hypothesis was designed
    to be testable, precise, and measurable. For example, one key hypothesis
    stated: "We believe that active seniors with an interest in culture and
    travel members of FAI are not checking the new events because of the high
    number of proposals. So if we select only the ones that might be attractive
    to them based on interests and location and show the smaller list to them,
    then more than half would read it and ask more questions about it."
</p>

<p>
    Through systematic experimentation,
    <strong>three needs were validated while two were not</strong>. The
    validated needs included better event comparison tools based on location and
    interests, more organized trip possibilities, and the use of FAI locations
    for celebrations like weddings. However, the local market concept and
    enhanced experiences for fitness enthusiasts did not validate, with
    <strong>less than 20% of test participants showing genuine interest</strong>
    in these features. This validation process helped focus resources on
    solutions that would genuinely serve user needs.
</p>

<h2>Solution Development and Assessment</h2>

<p>
    The team employed <strong>multiple divergent thinking methods</strong> to
    generate solution ideas. <em>Free-Wheeling Brainstorming</em> produced
    initial concepts, while the <em>Thinking Aloud</em> technique during user
    testing sessions revealed users' spontaneous suggestions. Benchmarking with
    similar organizations identified proven features, and <em>ChatGPT</em> was
    used with carefully engineered prompts to expand the solution space. The
    team used the <em>Prompt Canvas framework</em> to structure effective
    prompts, ensuring comprehensive exploration of AI-driven solutions.
</p>

<p>
    The solution development process
    <strong>converged on three main approaches</strong>. The
    <strong>interactive map solution</strong> provides a dynamic, user-friendly
    interface showcasing FAI locations with filtering capabilities based on user
    preferences. This solution was inspired by successful implementations on
    benchmarked sites like <em>New Zealand's National Trust</em>, where the map
    serves as a primary navigation tool on the homepage. The
    <strong>customizable email solution</strong>
    creates a direct communication channel where users submit natural language
    queries about their interests, geographical preferences, and travel
    willingness, receiving personalized event recommendations via email. The
    <strong>conversational chatbot solution</strong>, named
    <em>VirgilioGPT</em>, leverages GPT-4 to provide human-like interactions,
    helping users discover events through natural conversation rather than
    traditional website navigation.
</p>

<p>
    The team developed
    <strong>sophisticated metrics for solution assessment</strong>. The
    <em>Quality Index formula</em> combined time efficiency with user
    satisfaction using logarithmic transformation to avoid sparse scoring. The
    <strong
        >final assessment formula incorporated four normalized
        dimensions</strong
    >: time (inverted, as lower is better), satisfaction, engagement, and
    technical feasibility. This multi-dimensional approach provided a
    comprehensive evaluation framework that captured both quantitative
    performance and qualitative user experience factors.
</p>

<p>
    Solutions were tested using
    <a href="https://en.wikipedia.org/wiki/A/B_testing"> A/B testing </a>
    methodology with <strong>heterogeneous user groups</strong> representing
    different age ranges and backgrounds. For the map and baseline tests, users
    were asked to find specific events on different websites while time and
    satisfaction metrics were collected. The email solution was tested by having
    users navigate FAI's event page, then write descriptions of interesting
    events, which were processed using <em>ChatGPT</em> to generate personalized
    recommendations. The chatbot testing employed a split-screen framework with
    the FAI website on one side and <em>VirgilioGPT</em> chat on the other,
    allowing users to interact naturally with the AI assistant while browsing.
</p>

<h2>Results and Findings</h2>

<p>
    The assessment revealed
    <strong>clear performance differences among the three solutions</strong>.
    The <strong>interactive map achieved the highest overall score</strong> of
    13.16, demonstrating superior time efficiency with an average of 0.71 units,
    the highest satisfaction rating of 4.38 out of 5, and strong engagement at
    4.50. Technical feasibility was rated at 5.00, indicating the solution could
    be implemented with existing technology. The <em>email solution</em> scored
    6.78 overall, with moderate satisfaction (3.69) and good feasibility (4.00),
    but longer average task completion time of 4.42 units. The
    <em>chatbot solution</em> scored 7.56, achieving the highest engagement
    rating of 5.00 and strong satisfaction of 4.45, though
    <strong>feasibility was lower at 3.00</strong> due to technical constraints
    around response time.
</p>

<p>
    User feedback revealed <strong>several important patterns</strong>. Many
    users commented that events seemed too targeted toward families, suggesting
    an opportunity to diversify event marketing. The website's event page
    layout, with numerous events displayed simultaneously using large images and
    long titles, <strong>created disorientation rather than clarity</strong>.
    Several users expressed desire for event categorization by type, such as
    museum visits versus forest walks, and requested community-voted "best
    event" features. Users also sought
    <strong>more information about accessibility</strong> for elderly and
    disabled visitors, including details about host structures, safety ratings,
    and proximity to healthcare facilities.
</p>

<p>
    The map solution surprised the team by
    <strong>outperforming the UK National Trust website</strong>, which had been
    assumed to be superior due to additional features. Users found that
    <strong>excessive tools actually created confusion</strong>, as they simply
    wanted to find relevant events quickly. The email solution showed promise
    for collecting user contact information and enabling future engagement
    through periodic newsletters, though requiring users to leave the website
    was identified as a limitation. The chatbot solution generated
    <strong>strong user enthusiasm</strong>, with some users preferring
    conversation over traditional website navigation. However,
    <em>VirgilioGPT's</em> need to search the internet made it
    <u>too slow for practical deployment</u> without further optimization. The
    team noted that training a GPT specifically on FAI website content could
    resolve this issue, and identified commercial solutions that offer this
    capability.
</p>

<h2>Project Reflection</h2>

<p>
    The project faced <strong>several significant challenges</strong> that
    provided valuable learning opportunities.
    <strong>Recruiting appropriate test participants</strong> proved more
    difficult than anticipated, particularly for targeting the
    <em>active senior demographic</em>. The team adapted by conducting outreach
    through community centers and leveraging personal networks. Technical
    challenges emerged during chatbot development, as <em>VirgilioGPT's</em> web
    search functionality created latency. This required problem-solving and led
    to the discovery of commercial solutions that could address the issue.
    <strong>Balancing innovation with practical constraints</strong> required
    careful consideration throughout the solution development process.
</p>

<p>
    Our five-person team
    <strong>successfully navigated complex decision-making</strong> through
    structured processes including
    <em
        >Round-Robin Brainstorming, Brain-Writing, and Nominal Group
        Technique</em
    >. These methods ensured all voices were heard while maintaining project
    momentum. The team effectively combined individual expertise in data
    science, UX research, and technical implementation. Regular meetings and
    clear role assignments helped maintain coordination across research,
    development, and assessment activities. The
    <strong>integration of AI tools</strong> like <em>ChatGPT</em> demonstrated
    how teams can augment their capabilities while maintaining human judgment in
    critical decisions.
</p>

<p>
    The
    <strong
        >structured approach to user research, need validation, and solution
        assessment proved highly effective</strong
    >. The decision to evaluate and select research methods using explicit
    criteria prevented common pitfalls and ensured efficient resource split. The
    <em>need hypothesis framework</em> forced thinking about validation criteria
    before conducting experiments, improving the quality of insights. The
    <strong>multi-dimensional assessment formula</strong> provided understanding
    beyond simple rankings, revealing trade-offs between different solution
    characteristics.
    <u
        >This methodology could be effectively applied to other UX design
        projects</u
    >
    and product development initiatives.
</p>
