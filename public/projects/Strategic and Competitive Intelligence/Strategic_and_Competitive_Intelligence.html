<p>
    This project is a
    <strong>strategic and competitive intelligence analysis</strong> of the
    coding and software development field, in relation to
    <strong>generative AI</strong>, through
    <em>social media discourse analysis</em>. Conducted as part of a university
    course, the research explores how conversations about coding, emerging
    technologies, and professional practices unfold across multiple digital
    platforms including <a href="https://x.com/"> Twitter </a>,
    <a href="https://dev.to/"> Dev.to </a>,
    <a href="https://www.reddit.com/"> Reddit </a>, and
    <a href="https://stackoverflow.com/"> Stack Overflow </a>.
</p>

<p>
    The project addresses <strong>four critical research questions</strong> that
    provide insights into the current state and future direction of the software
    development industry. Through <em>natural language processing</em>,
    <em>text mining</em>, and <em>data visualization</em> techniques, the
    analysis uncovers
    <strong>patterns in how developers discuss innovations</strong>, evaluate
    companies, and adapt to changing work environments. The methodology combines
    quantitative analysis of large-scale datasets with qualitative
    interpretation of emerging trends, resulting in
    <strong>actionable intelligence</strong> for understanding the competitive
    landscape of technology companies and coding practices.
</p>

<p>
    The deliverable includes an
    <strong
        >interactive
        <a href="https://shiny.posit.co/"> R Shiny </a>
        dashboard</strong
    >
    that enables users to explore the findings through dynamic visualizations,
    making the intelligence accessible and actionable for various stakeholders
    including technology companies, educators, and industry analysts.
</p>

<h2>What I Learned</h2>
<p>
    This project is my <strong>first hands-on experience</strong> both using
    <em>R</em> and in applying strategic and competitive intelligence
    methodologies to real-world data sources. I learned how to
    <strong
        >transform unstructured social media data into actionable business
        intelligence</strong
    >
    through systematic analysis and visualization.
</p>

<p>
    One of the most significant learnings was mastering the
    <strong>entire cycle</strong>: from identifying relevant information sources
    to collecting, processing, analyzing, and disseminating findings. I
    developed proficiency in working with
    <strong>multiple APIs</strong> including <em>Twitter</em>, <em>Dev.to</em>,
    and <em>Reddit</em>, understanding their limitations and optimizing data
    collection strategies within rate limits and access constraints.
</p>

<p>
    The project deepened my understanding of
    <strong>natural language processing techniques</strong>, particularly
    <em>named entity recognition</em>, <em>sentiment analysis</em>, and
    <em>text classification</em> using libraries like
    <a href="https://www.nltk.org/"> NLTK </a>
    and
    <a href="https://spacy.io/"> spaCy </a>
    . I learned to <strong>filter noise from signal</strong> in large datasets
    containing millions of tweets, identifying meaningful patterns while
    managing computational resources efficiently.
</p>

<p>
    Building the <em>R Shiny dashboard</em> taught me the importance of
    <strong>data storytelling and user-centered design</strong> in intelligence
    reporting. I learned to translate complex analytical findings into
    visualizations including
    <a href="https://datavizcatalogue.com/methods/wordcloud.html">
        word clouds</a
    >,
    <a href="https://datavizcatalogue.com/methods/treemap.html"> treemaps </a>,
    and comparative charts that enable stakeholders to derive insights quickly.
</p>

<p>
    Perhaps most importantly, I learned the value of
    <strong>iterative refinement</strong> in intelligence gathering. The process
    of filtering company names, validating results through manual review, and
    continuously improving data quality demonstrated that
    <strong
        >competitive intelligence requires combining automated analysis with
        human judgment</strong
    >
    to produce reliable, actionable insights. This project reinforced that
    effective intelligence work is as much about critical thinking and domain
    knowledge as it is about technical skills.
</p>

<p>
    The project was structured around six research questions that guide the
    analysis of coding discourse and technology trends:
</p>

<h2>
    Question 1: What organizations are mentioned most often in the genAI for
    coding public discourse?
</h2>
<img
    src="quest1.png"
    alt="What organizations are mentioned most often in the genAI for coding public discourse?"
/>
<p>
    The takeaway from the data we gathered is that the
    <strong>organizations mentioned most often</strong> in the genAI for coding
    public discourse are mostly <strong>very big tech companies</strong>. There
    are some minor differences between the data extracted from
    <em>Twitter</em> and <em>Reddit</em> but not really meaningful ones since
    the most cited are always the same. In the list we found there are some
    interesting names that stand out when considering the names that one would
    assume to be more related to the generative AI public discussions (such as
    <em>NVIDIA</em>) and one can observe them in the treemap above.
</p>

<h2>
    Question 2: What innovative approaches or methodologies are emerging in the
    field of coding?
</h2>
<img
    src="quest2.png"
    alt="What innovative approaches or methodologies are emerging in the
    field of coding?"
/>
<p>
    We found that on <em>Twitter</em>, discussions revolve mostly around
    <strong>AI tech like "chatgpt"</strong>, as well as ongoing tech like
    <em>web3</em>, <em>IoT</em>, <em>AR</em>, and <em>metaverse</em>. The
    presence of "python" and "data" shows an interest in
    <strong>Data Science</strong>. Conversely, <em>Reddit</em> focuses more on
    specific companies like <em>Comcast</em> and <em>Google</em>. Important to
    note is that <strong>AI and cybersecurity are prevalent</strong>, as seen by
    mentions of terms like <em>NSA</em> and <em>WannaCry</em>.
    <em>Dev.To</em> data shows to be more <strong>developer-centric</strong>,
    focusing on tools and programming languages most used by professionals. Such
    can be seen by the high mentions of terms like <em>LLM</em>, <em>JMX</em>,
    and <em>Node.js</em>. What can be seen from all datasets is that
    <strong
        >AI and its derivations are a main part of the emerging technology
        landscape</strong
    >
    of today.
</p>

<h2>
    Question 3: Which programming languages were used before and after ChatGPT?
</h2>
<img
    src="quest3.png"
    alt="Which programming languages were used before and after ChatGPT?"
/>
<p>
    This analysis gathers data from <em>Dev.to</em> and <em>StackOverflow</em>.
    The above data represents mentions that programming languages received in
    <strong>2022 and 2023</strong>, before and after the release of
    <em>ChatGPT</em>. These mentions are generative AI agnostic. The analysis
    highlights
    <strong>small changes in the mention of programming languages</strong>
    before and after the release of ChatGPT. According to the data, the
    <strong
        >pace of innovation in Generative AI technology is higher than the pace
        of change in the adoption of programming languages</strong
    >. Limitations: ChatGPT was released in November 2022, hence this analysis
    only takes into consideration two years, 2022 and 2023. It would be
    interesting for future studies to look at a wider window of time.
</p>

<h2>
    Question 4: How are discussions about coding influenced by trends in remote
    work, digital nomadism, and gig economy employment, from the point of views
    of coding professionals?
</h2>
<img
    src="quest4.png"
    alt="How are discussions about coding influenced by trends in remote
    work, digital nomadism, and gig economy employment, from the point of views
    of coding professionals?"
/>
<p>
    Based on the data from <em>Dev.To</em>, it was observed that the
    <strong
        >prevailing opinions regarding remote working were predominantly
        positive</strong
    >. This indicates a favorable disposition towards emerging
    <em>digital nomadism</em> work arrangements. The main sentiments described
    this arrangement as <strong>easy, new, and available</strong>. Regarding
    <em>Twitter</em> the data shows that the
    <strong>predominant feelings are neutral and positive</strong>, that
    confirms the outcome of the research made on the <em>Dev.to</em> dataset.
    The topics that are mostly talked about in those discussions are visible in
    the treemap above.
</p>
<h2>
    Question 5: How do online conversations about competitive intelligence tools
    and software solutions compare in terms of user satisfaction, functionality,
    and ease of integration?
</h2>

<p>
    Based on online conversations and reviews, users are
    <strong
        >most satisfied with <em>Similarweb</em> and <em>Semrush</em></strong
    >
    when it comes to competitive intelligence tools and software solutions. This
    aligns with the findings of <em>Lopes et al. (2023)</em>, who conducted a
    bibliometric analysis to assess competitive intelligence and business
    intelligence concepts. In terms of <strong>functionality</strong>,
    <em>Similarweb</em> is often praised for its market research capabilities,
    <em>Sprout Social</em> for its social listening features,
    <em>Ahrefs</em> for its SEO tools, and <em>Semrush</em> is frequently
    mentioned as a comprehensive all-in-one solution. This is consistent with
    the systematic literature review by <em>Hatzijordanou et al. (2019)</em> on
    competitor analysis, which identifies and compares major market measurements
    that help distinguish the services and goods of the competitors. As for
    <strong>ease of integration</strong>, the general consensus is that these
    tools should ideally be able to integrate with existing systems like
    <em>Salesforce</em> and provide workbench capabilities for consolidated
    analysis. However, the
    <strong
        >best tool ultimately depends on specific requirements and
        budget</strong
    >.
    <u
        >It's always recommended to read user reviews before making a
        decision.</u
    >
</p>

<h4>Sources</h4>
<ul>
    <li>
        Lopes, B. de S., Amorim, V., Au-Yong-Oliveira, M., & Lima Rua, O.
        (2023). Competitive and Business Intelligence: A Bibliometric Analysis.
        In <em>Quality Innovation and Sustainability</em> (pp. 187–197).
        <a
            href="https://link.springer.com/chapter/10.1007/978-3-031-12914-8_15"
            target="_blank"
            >https://link.springer.com/chapter/10.1007/978-3-031-12914-8_15</a
        >
    </li>

    <li>
        Hatzijordanou, N., Bohn, N., & Terzidis, O. (2019). A systematic
        literature review on competitor analysis: status quo and start-up
        specifics. <em>Management Review Quarterly</em>, 69, 415–458.
        <a
            href="https://link.springer.com/article/10.1007/s11301-019-00158-5"
            target="_blank"
            >https://link.springer.com/article/10.1007/s11301-019-00158-5</a
        >
    </li>

    <li>
        G2. (2024). Best Competitive Intelligence Tools in 2024.
        <a
            href="https://www.g2.com/categories/competitive-intelligence"
            target="_blank"
            >https://www.g2.com/categories/competitive-intelligence</a
        >
    </li>

    <li>
        G2. (2024). Best Enterprise Competitive Intelligence Tools in 2024.
        <a
            href="https://www.g2.com/categories/competitive-intelligence/enterprise"
            target="_blank"
            >https://www.g2.com/categories/competitive-intelligence/enterprise</a
        >
    </li>

    <li>
        G2. (2024). Best Competitive Intelligence Tools for Small Business.
        <a
            href="https://www.g2.com/categories/competitive-intelligence/small-business"
            target="_blank"
            >https://www.g2.com/categories/competitive-intelligence/small-business</a
        >
    </li>

    <li>
        G2. (2024). Best Competitive Intelligence Tools for Medium-Sized
        Businesses.
        <a
            href="https://www.g2.com/categories/competitive-intelligence/mid-market"
            target="_blank"
            >https://www.g2.com/categories/competitive-intelligence/mid-market</a
        >
    </li>

    <li>
        Zapier. (2024). The 9 best competitor analysis tools in 2024.
        <a
            href="https://zapier.com/blog/competitor-analysis-tools/"
            target="_blank"
            >https://zapier.com/blog/competitor-analysis-tools/</a
        >
    </li>

    <li>
        Evalueserve. (n.d.). Competitive Intelligence Solutions: 5 Ways to Ease
        Your Job.
        <a
            href="https://www.evalueserve.com/blog/competitive-intelligence-solutions-easier-job/"
            target="_blank"
            >https://www.evalueserve.com/blog/competitive-intelligence-solutions-easier-job/</a
        >
    </li>

    <li>
        Content Boomerang. (n.d.). Competitive Intelligence Tools: Key Solutions
        for Strategic Business.
        <a
            href="https://contentboomerang.com/blog/competitive-intelligence-tools/"
            target="_blank"
            >https://contentboomerang.com/blog/competitive-intelligence-tools/</a
        >
    </li>

    <li>
        Semrush. (n.d.). The 14 Best Competitive Intelligence Tools for Market
        Research.
        <a
            href="https://www.semrush.com/blog/best-competitive-intelligence-tools/"
            target="_blank"
            >https://www.semrush.com/blog/best-competitive-intelligence-tools/</a
        >
    </li>
</ul>

<h2>
    Question 6: What are the ethical implications of using genAI-driven
    competitive intelligence tools to gather and analyze data from competitor
    websites and social media profiles?
</h2>

<p>
    <strong>1. Quantitative attempt:</strong> We first tried to answer this
    question using the same strategy of the previous answers. Definition of key
    words, filtering of relevant tweets, aggregation of data. In this case we
    tried filtering tweets by ethical key words and names of competitive
    intelligence tools. After that, we wanted to obtain the median value on the
    variable sentiment, in order to do a sentiment analysis regarding the
    perception of ethics in these tools.
</p>

<p>
    <strong>2. Missing data:</strong> Tools of competitive intelligence are
    mostly using <strong>simple machine learning algorithms</strong>. Of the 22
    tools we found,
    <strong
        >all of them were not exploiting the potential of generative AI</strong
    >.
</p>

<p>
    <strong>3. Role of NLU:</strong> Researches are being conducted in the
    arising field of tools for strategic and competitive intelligence using
    generative AI, but mostly are focused on the use of these powerful models as
    <strong
        ><em>NLU</em>, in order to process huge quantities of text data</strong
    >
    with greater understanding.
</p>

<p>
    <strong>4. Ethical implications:</strong> Ethical implications in this field
    regard therefore mostly the
    <strong>issues arising by conducting web scraping practices</strong>, such
    as <em>illegal access and use of data</em>, <em>breach of contract</em>,
    <em>copyright</em>, <em>trespass to chattels</em>, and
    <em>trade secrets</em>.
</p>

<h4>Sources</h4>
<ul>
    <li>
        De Los Reyes, D., Trajano, D., Manssour, I., Vieira, R., & Bordini, R.
        (2021). Entity Relation Extraction from News Articles in Portuguese for
        Competitive Intelligence Based on BERT. In
        <em>Advances in Artificial Intelligence</em> (pp. 431-442). Springer.
        <a href="https://doi.org/10.1007/978-3-030-91699-2_31" target="_blank"
            >https://doi.org/10.1007/978-3-030-91699-2_31</a
        >
    </li>

    <li>
        Krotov, V., Johnson, L., & Silva, L. (2020). Tutorial: Legality and
        Ethics of Web Scraping.
        <em>Communications of the Association for Information Systems</em>, 47,
        24.
        <a href="https://doi.org/10.17705/1CAIS.04724" target="_blank"
            >https://doi.org/10.17705/1CAIS.04724</a
        >
    </li>
</ul>

<h2>Technical Implementation</h2>
<p>
    The project spanned
    <strong>large-scale data collection, processing, and visualization</strong>
    across multiple platforms and data sources.
</p>

<p>
    Data gathering utilized
    <strong>multiple APIs and web scraping techniques</strong>. The
    <em>Twitter</em> analysis leveraged a pre-existing
    <em>ChatGPT Tweets Dataset</em> containing
    <strong>3.8 million records</strong> with rich metadata including subjects,
    objects, topics, and job profiles. For <em>Dev.to</em>, the official API was
    used with custom pagination logic to retrieve articles matching specific
    tags and search queries, collecting data across 10 pages with 1,000 articles
    per page. <em>Reddit</em> data collection employed the
    <a href="https://praw.readthedocs.io/en/stable/"> PRAW </a>
    library to search the technology subreddit, retrieving posts and up to 1,000
    top comments per post ranked by score. <em>Stack Overflow</em> survey data
    was obtained through web crawling of official survey result pages.
</p>

<p>
    The <strong>NLP pipeline integrated multiple libraries</strong> for
    different analysis tasks. <em>NLTK</em> provided tokenization, stopword
    removal, and part-of-speech tagging for extracting noun phrases and
    identifying technical terminology. <em>spaCy's</em> models enabled
    <strong>named entity recognition</strong> to identify companies,
    technologies, and proper nouns within text. Custom filtering logic combined
    regex patterns with predefined keyword lists to isolate coding-related
    content from the broader dataset. For sentiment analysis, the project
    leveraged <em>spaCy's</em>
    linguistic features to identify adjectives and sentiment-bearing terms.
</p>

<p>
    Given the <strong>massive scale of the Twitter dataset (3.8M rows)</strong>,
    <strong>efficient filtering was critical</strong>. The implementation used
    <em>pandas</em> for vectorized operations, filtering the dataset by creating
    lowercase column versions and applying regex patterns for 100+
    coding-related keywords. This
    <strong>reduced the dataset to approximately 1.47 million</strong>
    coding-relevant tweets. For company name extraction, the process involved
    multiple stages: initial automated extraction, frequency counting, filtering
    by minimum thresholds, and
    <strong>manual validation through an interactive Python script</strong> that
    prompted review of 200 companies.
</p>

<p>
    You can explore all the jupyter notebooks used in this phase at this
    <a
        href="https://github.com/AlessandroCarella/Strategic-and-competitive-intelligence/tree/main/data%20gathering"
    >
        link
    </a>
</p>

<p>
    The
    <strong><em>R Shiny</em> dashboard serves as the primary interface</strong>
    for exploring findings. Built with a modular structure (<em>ui.R</em>,
    <em>server.R</em>, <em>app.R</em>), the dashboard implements
    <strong>reactive programming</strong> to handle user interactions
    efficiently. Visualization libraries include <em>plotly</em> for interactive
    charts, <em>wordcloud2</em> for frequency visualizations,
    <em>ggplot2</em> for statistical graphics, and <em>treemap</em> for
    hierarchical data representation. The dashboard loads data reactively,
    rendering visualizations only when needed to optimize performance.
</p>

<p>
    The project demonstrates
    <strong
        >effective integration of Python for data processing and R for
        visualization</strong
    >. <em>Python</em> notebooks handled ETL operations, API interactions, and
    NLP tasks, exporting cleaned datasets as CSV files. <em>R Shiny</em> handles
    these outputs to create the final analytical interface. This
    <strong>multi-language approach used the strengths of each ecosystem</strong
    >: Python's extensive API and NLP libraries for data gathering, and R's
    visualization capabilities for presentation.
</p>

<h2>Challenges and Solutions</h2>
<p>
    The project encountered
    <strong>numerous technical and methodological challenges</strong>
    that required creative problem-solving and adaptive strategies.
</p>

<p>
    Working with
    <strong>3.8 million tweet records strained computational resources</strong>
    and processing time. The initial naive approach of iterating through rows
    proved impractical, taking hours to process. The solution involved using
    <strong><em>pandas'</em> vectorized operations</strong>, creating lowercase
    column versions for case-insensitive matching, and applying regex patterns
    across entire columns simultaneously. This optimization
    <strong>reduced processing time from hours to minutes</strong>. For company
    name extraction, implementing incremental processing and saving intermediate
    results protected against data loss from crashes or interruptions.
</p>

<p>
    Each API imposed <strong>different constraints on data access</strong>.
    <em>Dev.to's</em> beta API had limited filtering accuracy despite accepting
    tag and query parameters, requiring additional client-side filtering.
    <em>Reddit's</em> API limited comment retrieval, necessitating
    prioritization strategies to capture top comments by score. The solution
    implemented
    <strong>pagination with appropriate delays between requests</strong>, retry
    logic for failed requests, and batch processing to respect rate limits while
    maximizing data collection efficiency.
</p>

<p>
    Off-the-shelf <em>NER models</em> produced
    <strong>significant false positives</strong> when identifying company names.
    Common English words like "next," "test," "nothing," "yes," and "current"
    were incorrectly classified as organizations. Conversely, some actual
    companies like <em>Binance</em> and <em>Nothing</em> (the actual tech
    company) required special handling. The solution implemented a
    <strong>multi-stage validation process</strong>: automated extraction with
    frequency thresholds, manual review through an interactive script, and
    frequency adjustment factors for ambiguous terms. Words that were both
    companies and common terms received reduced frequency weights (divided by 50
    instead of 300) to account for probable legitimate mentions.
</p>

<p>
    <strong>Different platforms structured data differently</strong>,
    complicating comparative analysis. <em>Twitter</em> provided subjects,
    objects, and predicates; <em>Dev.to</em> offered tags and descriptions;
    <em>Reddit</em> had titles and comments; <em>Stack Overflow</em> used survey
    questions. The solution
    <strong
        >standardized data through platform-specific preprocessing
        pipelines</strong
    >
    that extracted comparable features: textual content, metadata categories,
    temporal information, and frequency counts. Creating normalized CSV exports
    enabled consistent analysis in the <em>R Shiny dashboard</em>
    regardless of source platform.
</p>

<h2>Extra Deliverable: Stack Overflow Advanced Data Scraper</h2>
<p>
    As an additional contribution to the Strategic and Competitive Intelligence
    project, I developed a
    <strong
        >sophisticated R-based tool for extracting structured data from
        <em>Stack Overflow</em></strong
    >. This
    <a
        href="https://github.com/AlessandroCarella/Strategic-and-competitive-intelligence/tree/main/ZZZ%20Deliverable%20for%201%20extra%20point/Proposal%201/Carella_Alessandro"
    >
        custom scraper
    </a>
    served us for the data gathering phase.
</p>

<p>
    The scraper implements a <strong>modular architecture</strong> with clear
    separation of concerns across seven <em>R scripts</em>. The
    <em>main.r</em> file orchestrates the entire workflow, coordinating query
    formulation, link collection, data extraction, and output generation. The
    <em>classes.r</em> module defines
    <strong><em>R6</em> object-oriented structures</strong> for Questions,
    Answers, and Comments, enabling hierarchical data modeling that preserves
    the natural structure of <em>Stack Overflow</em> content. The
    <em>queryOptions.r</em> system handles
    <strong>advanced query formulation</strong>, supporting all Stack Overflow
    search operators including tags, score thresholds, view counts, and code
    snippets.
</p>

<p>
    The tool supports
    <strong>filtering through Stack Overflow's search syntax</strong>, enabling
    users to construct precise queries. Users can filter by tags like
    <em>python</em> or <em>opencv</em> while excluding others, specify minimum
    scores to focus on high-quality questions, require minimum answer counts to
    ensure solutions exist, and sort by view counts to identify
    widely-encountered problems. The system can even
    <strong>search for specific code patterns</strong>, enabling identification
    of how particular APIs or functions are being used in practice. Support for
    closed/duplicate filtering helps focus on active, unique questions. The
    query builder works both interactively through prompts and programmatically
    through parameter passing, providing flexibility for different use cases.
</p>

<p>
    The scraping engine leverages the
    <strong><em>rvest</em> package for robust HTML parsing</strong> with XPath
    and CSS selectors. The <em>getAllQuestionsLinks.r</em> module implements
    <strong>intelligent pagination</strong>, automatically requesting additional
    pages until the desired number of results is collected, with each page
    containing up to 50 questions.
    <strong>Captcha detection and handling</strong> is built-in, with the system
    pausing when it detects a challenge and prompting the user to solve it
    before continuing. The <em>extractDataFromQuestionPage.r</em> module
    performs <strong>deep extraction from individual question pages</strong>,
    parsing the hierarchical structure of questions, their multiple answers, and
    nested comments.
</p>

<p>
    For each question, the scraper extracts the full title,
    <strong>vote count indicating community value</strong>, complete question
    text preserving formatting, all code snippets separately identified, and
    total answer count. For each answer, it captures the unique answer ID for
    tracking, complete answer text with formatting, all code blocks within the
    answer, <strong>vote count showing community validation</strong>, and the
    full comment thread with user attribution.
</p>

<p>
    The tool generates
    <strong>outputs optimized for different analysis scenarios</strong>.
</p>

<p>
    <strong><em>CSV format</em></strong> exports tabular data including question
    titles, votes, answer statistics, and aggregate metrics like total votes
    across all answers and comment counts. This format is ideal for
    <strong
        >quantitative analysis, statistical processing, and dashboard
        integration</strong
    >.
</p>

<p>
    <strong><em>YAML format</em></strong> preserves the complete hierarchical
    structure including full text content of questions, answers, and comments,
    code snippets with proper formatting, and nested comment threads. This
    format is perfect for
    <strong
        >qualitative analysis, content mining, and detailed case studies</strong
    >.
</p>

<p>
    <strong><em>JSON format</em></strong> stores the collected question links,
    enabling <strong>checkpointing and reproducibility</strong> of data
    collection sessions.
</p>
